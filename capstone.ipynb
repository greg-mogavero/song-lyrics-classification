{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Song Lyric Classification By Artist\n",
    "#### Udacity Machine Learning Nanodegree Capstone Project\n",
    "#### Greg Mogavero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description\n",
    "---\n",
    "Machine learning is commonly used to perform [natural language processing](https://en.wikipedia.org/wiki/Natural_language_processing) (NLP), a “field of computer science, artificial intelligence and computational linguistics concerned with the interactions between computers and human (natural) languages, and, in particular, concerned with programming computers to fruitfully process large natural language corpora.” One particular use case for NLP is analyzing song lyrics to classify them by artist. A successful machine learning algorithm would not only have to take into account the songwriter’s lexicon, but also pick up on the unique subtleties of the artist’s style in order to differentiate artists who write about similar topics.\n",
    "\n",
    "Efforts have already been made by the machine learning community to classify songs based on their lyrics by genre and artist. [Sadovsky and Chen](https://nlp.stanford.edu/courses/cs224n/2006/fp/sadovsky-x1n9-1-224n_final_report.pdf) used Maxent and SVM classifiers to accomplish this task fairly successfully. Using no acoustic information whatsoever, they were able to achieve 70-80% artist classification accuracy. Because they used Bag of Words for feature selection, they remark that they might have been able to achieve higher accuracy if they did some sort of semantic analysis.\n",
    "For this project, I will be using a [dataset](https://www.kaggle.com/mousehead/songlyrics) comprised of 57,650 song lyrics scraped from LyricsFreak by Sergey Kuznetsov.\n",
    "\n",
    "Given song lyrics (text only) as input and the corresponding artists as labels, I will attempt to build a supervised learner that can classify new songs by artist. Input will be truncated or padded during preprocessing so that each sample is a fixed size.\n",
    "\n",
    "I will attempt to solve the problem of classifying song lyrics by artist by training a Long Short Term Memory (LSTM) Neural Network. These models, when trained on text data, can “remember” information they have seen in the past. I hypothesize that the ability to learn this contextual information will help the learner distinguish songs by different artists who have similar lexicons, but different styles.\n",
    "\n",
    "In order to get meaningful results, I will choose the 10 artists from the dataset with the largest repertoire of songs. After preprocessing the input text data using Word2Vec, I will train and test a basic LSTM network, analyze its performance, and then try to improve results through hyperparameter tuning and architecture modification. Final results will be compared against a benchmark model based on the models Sadovsky and Chen used in their experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "---\n",
    "The first thing we'll do is import the dataset into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>Look at her face, it's a wonderful face  \\nAnd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>Take it easy with me, please  \\nTouch me gentl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>I'll never know why I had to go  \\nWhy I had t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang</td>\n",
       "      <td>/a/abba/bang_20598415.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang-A-Boomerang</td>\n",
       "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                   song                                        link  \\\n",
       "0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       "1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n",
       "2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n",
       "3   ABBA                   Bang                  /a/abba/bang_20598415.html   \n",
       "4   ABBA       Bang-A-Boomerang      /a/abba/bang+a+boomerang_20002668.html   \n",
       "\n",
       "                                                text  \n",
       "0  Look at her face, it's a wonderful face  \\nAnd...  \n",
       "1  Take it easy with me, please  \\nTouch me gentl...  \n",
       "2  I'll never know why I had to go  \\nWhy I had t...  \n",
       "3  Making somebody happy is a question of give an...  \n",
       "4  Making somebody happy is a question of give an...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "raw_data = pd.read_csv(\"./songdata.csv\")\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's drop the columns we don't need. Let's also count the number of songs by each artist, print a description of these statistics, and print the top 10 artists with the most songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>643.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>89.657854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>54.689192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>86.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>141.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       song count\n",
       "count  643.000000\n",
       "mean    89.657854\n",
       "std     54.689192\n",
       "min      1.000000\n",
       "25%     41.000000\n",
       "50%     86.000000\n",
       "75%    141.000000\n",
       "max    191.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = raw_data.drop([\"song\", \"link\"], axis=1)\n",
    "num_songs_per_artist = data.groupby([\"artist\"], as_index=False).count().rename(columns={\"text\": \"song count\"})\n",
    "\n",
    "num_songs_per_artist.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donna Summer</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gordon Lightfoot</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bob Dylan</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>George Strait</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cher</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Reba Mcentire</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Loretta Lynn</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dean Martin</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chaka Khan</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             artist  song count\n",
       "0      Donna Summer         191\n",
       "1  Gordon Lightfoot         189\n",
       "2         Bob Dylan         188\n",
       "3     George Strait         188\n",
       "4              Cher         187\n",
       "5           Alabama         187\n",
       "6     Reba Mcentire         187\n",
       "7      Loretta Lynn         187\n",
       "8       Dean Martin         186\n",
       "9        Chaka Khan         186"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_songs_per_artist.sort_values(\"song count\", inplace=True, ascending=False)\n",
    "num_songs_per_artist.reset_index(drop=True, inplace=True)\n",
    "num_songs_per_artist[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the number of songs per artist ranges from 1 to 191, with a mean of 89.658 and a standard deviation of 54.689. If we were to use the entire dataset, we would see a big class imbalance, and the supervised learner would struggle to learn anything meaningful about the artists with a relatively small number of songs. But if we just use the 10 artists with the most songs, we get a dataset with fairly balanced classes. This also ensures we will get a meaningful accuracy score when evaluating our model's performance. Let's reduce our dataset down to these 10 artists now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>187.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.505545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>186.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>187.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>187.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>188.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       song count\n",
       "count   10.000000\n",
       "mean   187.600000\n",
       "std      1.505545\n",
       "min    186.000000\n",
       "25%    187.000000\n",
       "50%    187.000000\n",
       "75%    188.000000\n",
       "max    191.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data[\"artist\"].map(lambda x: x in num_songs_per_artist[\"artist\"][:10].values)]\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# describe the stats of the new dataset\n",
    "data.groupby([\"artist\"], as_index=False).count().rename(columns={\"text\": \"song count\"}).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can see that the new dataset is much more balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Preprocessing\n",
    "---\n",
    "For the first step of preprocessing the data, we need to convert the words in our text input into numerical representations. I chose to represent each word by its frequency rank, and the rank ascends from most frequent word to the least frequent word. Rank 0 is special in that it represents words that we won't consider because they appear too infrequently. The maximum number of words to consider can be passed as a parameter to the words_to_index() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing...\n",
      "Finished tokenizing after 0.063s\n",
      "Converting words to indices...\n",
      "Finished after 0.057s\n",
      "Dumping data...\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import pickle\n",
    "from time import time\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "def words_to_index(data, column, max_words=None, fp=None):\n",
    "    \"\"\"Translates words into integers representing their frequency rank.\n",
    "    \n",
    "    Parameters:\n",
    "    data -- A Pandas DataFrame.\n",
    "    column -- The label of the column to process.\n",
    "    max_words -- The maximum number of most common words to consider. A value of None means all words will be considered.\n",
    "    fp -- The filepath to save the Pickle dump of the processed dataset.\n",
    "    \n",
    "    Returns:\n",
    "    new_data -- A list of lists containing the processed data.\n",
    "    index -- A dict mapping words to their index.\n",
    "    \"\"\"\n",
    "    # First tokenize the entire corpus of song lyrics into a flattened list\n",
    "    words = []\n",
    "    song_indices = [0]\n",
    "    last_index = 0\n",
    "    print(\"Tokenizing...\")\n",
    "    start = time()\n",
    "    for sample in data[column].values:\n",
    "        tokens = text_to_word_sequence(sample)\n",
    "        song_indices.append(len(tokens) + last_index)\n",
    "        words.extend(tokens)\n",
    "        last_index += len(tokens)\n",
    "    print(\"Finished tokenizing after {:.3f}s\".format(time() - start))\n",
    "    \n",
    "    # Count each word, then build an index out of the most common words\n",
    "    count = [(\"NULL\", -1)]\n",
    "    count.extend(collections.Counter(words).most_common(max_words))\n",
    "    index = {}\n",
    "    for word, _ in count:\n",
    "        index[word] = len(index)\n",
    "    reverse_index = dict(zip(index.values(), index.keys()))\n",
    "        \n",
    "    # Convert the words in each song into their numerical representations using the index\n",
    "    new_data = []\n",
    "    print(\"Converting words to indices...\")\n",
    "    start = time()\n",
    "    for i in range(data.shape[0]):\n",
    "        new_sample = []\n",
    "        sample = words[song_indices[i]:song_indices[i+1]]\n",
    "        for word in sample:\n",
    "            if word in index:\n",
    "                new_sample.append(index[word])\n",
    "            else:\n",
    "                new_sample.append(0)\n",
    "        new_data.append(new_sample)\n",
    "    print(\"Finished after {:.3f}s\".format(time() - start))\n",
    "    \n",
    "    # If a filepath is provided, dump the processed dataset to disk\n",
    "    if fp != None:\n",
    "        print(\"Dumping data...\")\n",
    "        with open(fp, \"wb\") as f:\n",
    "            pickle.dump((new_data, index, reverse_index), f)\n",
    "            \n",
    "    return new_data, index, reverse_index\n",
    "\n",
    "pp_data, index, reverse_index = words_to_index(data, \"text\", max_words=5000, fp=\"./word_indices.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Checkpoint*\n",
    "With the words converted into integer representations, we can now turn them into word embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2  215   11   40  244    2  215   11  119  163  243  185    5   91   11\n",
      "    6 2797   10    9  481    3  259  208   63  299   26    3 4227   13  248\n",
      "   48   18 1223   99  164    8   42  178   40  131  428  547    5  292   17\n",
      "    1 1610  337    3  101   17    1  881   40  699   42  178   40  131 1110\n",
      "  180   39  173   19  173    2  138   92  461   18 2751  302   46  200    1\n",
      "  585  139    3   64  135    6   90   89   38    3   64  135    6   90   89\n",
      "   38   39   32    3   64  135    6   90   89   38 1175    3   64  135    6\n",
      "   90   89   38   71  838   46    8    9 2353  730   13    2  271    4   92\n",
      "   11    5    1  753    2  138   15  254   20   95   71  227   14    9  258\n",
      " 2022   14  116  863  251    2   54   48    3  215    3   79  358    7 3850\n",
      "    7    5   16 2964    0    7   14   16 1065   77    7  114    3   41   65\n",
      "   31  835   20    3   49    2   24  358   13 1406  139    3   64  135    6\n",
      "   90   89   38    3   64  135    6   90   89   38   39   32    3   64  135\n",
      "    6   90   89   38 1175    3   64  135    6   90   89   38   58   15   52\n",
      "   66   14    1 1083  869   28    9  341   41 1496   71   54    7 2459  100\n",
      "   18  831  122   36    5 2864    3   67    9  528   24  964  218 1546   24\n",
      "  206    7   14    1  780   24  748   14    9  248  172    5    3   18   62\n",
      "   72   94    2   27   84    6  251   52   66   20    6   89   33    7  139\n",
      "    3   64  135    6   90   89   38    3   64  135    6   90   89   38   39\n",
      "   32    3   64  135    6   90   89   38 1175    3   64  135    6   90   89\n",
      "   38   39  173   19  173    2  138   92  461   18 2751  302   46  200    1\n",
      "  585  139    3   64  135    6   90   89   38   49    3   64  135    6   90\n",
      "   89   38  269    3   64  135    6   90   89   38 1175    3   64  135    6\n",
      "   90   89   38    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "with open(\"./word_indices.pkl\", \"rb\") as f:\n",
    "    pp_data, index, reverse_index = pickle.load(f)\n",
    "\n",
    "pp_data = pad_sequences(pp_data, maxlen=500, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
