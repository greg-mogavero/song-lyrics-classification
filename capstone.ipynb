{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Song Lyric Classification By Artist\n",
    "#### Udacity Machine Learning Nanodegree Capstone Project\n",
    "#### Greg Mogavero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description\n",
    "---\n",
    "Machine learning is commonly used to perform [natural language processing](https://en.wikipedia.org/wiki/Natural_language_processing) (NLP), a “field of computer science, artificial intelligence and computational linguistics concerned with the interactions between computers and human (natural) languages, and, in particular, concerned with programming computers to fruitfully process large natural language corpora.” One particular use case for NLP is analyzing song lyrics to classify them by artist. A successful machine learning algorithm would not only have to take into account the songwriter’s lexicon, but also pick up on the unique subtleties of the artist’s style in order to differentiate artists who write about similar topics.\n",
    "\n",
    "Efforts have already been made by the machine learning community to classify songs based on their lyrics by genre and artist. [Sadovsky and Chen](https://nlp.stanford.edu/courses/cs224n/2006/fp/sadovsky-x1n9-1-224n_final_report.pdf) used Maxent and SVM classifiers to accomplish this task fairly successfully. Using no acoustic information whatsoever, they were able to achieve 70-80% artist classification accuracy. Because they used Bag of Words for feature selection, they remark that they might have been able to achieve higher accuracy if they did some sort of semantic analysis.\n",
    "For this project, I will be using a [dataset](https://www.kaggle.com/mousehead/songlyrics) comprised of 57,650 song lyrics scraped from LyricsFreak by Sergey Kuznetsov.\n",
    "\n",
    "Given song lyrics (text only) as input and the corresponding artists as labels, I will attempt to build a supervised learner that can classify new songs by artist. Input will be truncated or padded during preprocessing so that each sample is a fixed size.\n",
    "\n",
    "I will attempt to solve the problem of classifying song lyrics by artist by training a Long Short Term Memory (LSTM) Neural Network. These models, when trained on text data, can “remember” information they have seen in the past. I hypothesize that the ability to learn this contextual information will help the learner distinguish songs by different artists who have similar lexicons, but different styles.\n",
    "\n",
    "In order to get meaningful results, I will choose the 10 artists from the dataset with the largest repertoire of songs. After preprocessing the input text data using Word2Vec, I will train and test a basic LSTM network, analyze its performance, and then try to improve results through hyperparameter tuning and architecture modification. Final results will be compared against a benchmark model based on the models Sadovsky and Chen used in their experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "---\n",
    "The first thing we'll do is import the dataset into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>Look at her face, it's a wonderful face  \\nAnd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>Take it easy with me, please  \\nTouch me gentl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>I'll never know why I had to go  \\nWhy I had t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang</td>\n",
       "      <td>/a/abba/bang_20598415.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang-A-Boomerang</td>\n",
       "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                   song                                        link  \\\n",
       "0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       "1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n",
       "2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n",
       "3   ABBA                   Bang                  /a/abba/bang_20598415.html   \n",
       "4   ABBA       Bang-A-Boomerang      /a/abba/bang+a+boomerang_20002668.html   \n",
       "\n",
       "                                                text  \n",
       "0  Look at her face, it's a wonderful face  \\nAnd...  \n",
       "1  Take it easy with me, please  \\nTouch me gentl...  \n",
       "2  I'll never know why I had to go  \\nWhy I had t...  \n",
       "3  Making somebody happy is a question of give an...  \n",
       "4  Making somebody happy is a question of give an...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "raw_data = pd.read_csv(\"./songdata.csv\")\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's drop the columns we don't need. Let's also count the number of songs by each artist, print a description of these statistics, and print the top 10 artists with the most songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>643.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>89.657854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>54.689192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>86.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>141.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       song count\n",
       "count  643.000000\n",
       "mean    89.657854\n",
       "std     54.689192\n",
       "min      1.000000\n",
       "25%     41.000000\n",
       "50%     86.000000\n",
       "75%    141.000000\n",
       "max    191.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = raw_data.drop([\"song\", \"link\"], axis=1)\n",
    "num_songs_per_artist = data.groupby([\"artist\"], as_index=False).count().rename(columns={\"text\": \"song count\"})\n",
    "\n",
    "num_songs_per_artist.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donna Summer</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gordon Lightfoot</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bob Dylan</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>George Strait</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cher</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             artist  song count\n",
       "0      Donna Summer         191\n",
       "1  Gordon Lightfoot         189\n",
       "2         Bob Dylan         188\n",
       "3     George Strait         188\n",
       "4              Cher         187"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_songs_per_artist.sort_values(\"song count\", inplace=True, ascending=False)\n",
    "num_songs_per_artist.reset_index(drop=True, inplace=True)\n",
    "num_songs_per_artist[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the number of songs per artist ranges from 1 to 191, with a mean of 89.658 and a standard deviation of 54.689. If we were to use the entire dataset, we would see a big class imbalance, and the supervised learner would struggle to learn anything meaningful about the artists with a relatively small number of songs. But if we just use the 10 artists with the most songs, we get a dataset with fairly balanced classes. This also ensures we will get a meaningful accuracy score when evaluating our model's performance. Let's reduce our dataset down to these 10 artists now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>188.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.516575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>187.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>188.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>188.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>189.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       song count\n",
       "count    5.000000\n",
       "mean   188.600000\n",
       "std      1.516575\n",
       "min    187.000000\n",
       "25%    188.000000\n",
       "50%    188.000000\n",
       "75%    189.000000\n",
       "max    191.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data[\"artist\"].map(lambda x: x in num_songs_per_artist[\"artist\"][:5].values)]\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# describe the stats of the new dataset\n",
    "data.groupby([\"artist\"], as_index=False).count().rename(columns={\"text\": \"song count\"}).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can see that the new dataset is much more balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Model\n",
    "---\n",
    "For my benchmark, I will use an SVM classifier (like in Sadovsky and Chen's experiment) on the preprocessed song lyrics. However, my model is much simpler and only uses sklearn's CountVectorizer with mostly default parameters to create the bag of words, whereas Sadovsky and Chen first found word importances through a maxent classifier and constructed the bag of words using only the most important features. Given that this is just a benchmark model, I elected to go with a quicker, simpler solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark accuracy score: 0.397\n",
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAH+CAYAAAABPw0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2697e359a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from visualization import plot_confusion_matrix\n",
    "\n",
    "y = data[\"artist\"]\n",
    "cv = CountVectorizer(stop_words=\"english\", max_features=250)\n",
    "X = cv.fit_transform(data[\"text\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "clf = SVC(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Benchmark accuracy score: {:.3f}\".format(accuracy_score(y_test, pred)))\n",
    "class_names = data[\"artist\"].unique()\n",
    "plt.figure(figsize=(7, 7))\n",
    "plot_confusion_matrix(confusion_matrix(y_test, pred, labels=class_names), class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "With 5 labels and only considering the 250 most frequent words (stopwords removed), the benchmark model achieved an accuracy score of 39.7%. This is better than random guessing, and it means that supervised learners can learn to distinguish artists with some success based on word frequency alone. This makes sense since artists generally sing about a wide variety of topics, and different artists might sing about the same topic.\n",
    "\n",
    "Once again it's important to note that we can't use Sadovsky and Chen's results as a benchmark (they achieved around 70% accuracy for artist classification) because our dataset is different and they used more complex preprocessing methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Preprocessing\n",
    "---\n",
    "For the first step of preprocessing the data, we need to convert the words in our text input into numerical representations. I chose to represent each word by its frequency rank, and the rank ascends from most frequent word to the least frequent word. Rank 0 is special in that it represents words that we won't consider because they appear too infrequently. The maximum number of words to consider can be passed as a parameter to the words_to_index() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing...\n",
      "Finished tokenizing after 0.035s\n",
      "Converting words to indices...\n",
      "Finished after 0.034s\n",
      "\n",
      "Example song before preprocessing\n",
      "--------------------------------------------------------------------------------\n",
      "When she said, \"Don't waste your words, they're just lies,\"  \n",
      "I cried she was deaf.  \n",
      "And she worked on my face until breaking my eyes,  \n",
      "Then said, \"What else you got left?\"  \n",
      "It was then that I got up to leave  \n",
      "But she said, \"Don't forget,  \n",
      "Everybody must give something back  \n",
      "For something they get.\"  \n",
      "  \n",
      "I stood there and hummed,  \n",
      "I tapped on her drum  \n",
      "And asked her how come.  \n",
      "And she buttoned her boot,  \n",
      "And straightened her suit,  \n",
      "Then she said, \"Don't get cute.\"  \n",
      "So I forced my hands in my pockets  \n",
      "And felt with my thumbs,  \n",
      "And gallantly handed her  \n",
      "My very last piece of gum.  \n",
      "  \n",
      "She threw me outside,  \n",
      "I stood in the dirt where ev'ryone walked.  \n",
      "And after finding I'd forgotten my shirt,  \n",
      "I went back and knocked.  \n",
      "I waited in the hallway, she went to get it,  \n",
      "And I tried to make sense  \n",
      "Out of that picture of you in your wheelchair  \n",
      "That leaned up against--  \n",
      "  \n",
      "Her Jamaican rum  \n",
      "And when she did come, I asked her for some.  \n",
      "She said, \"No, dear.\"  \n",
      "I said, \"Your words aren't clear,  \n",
      "You'd better spit out your gum.\"  \n",
      "She screamed till her face got so red,  \n",
      "Then she fell on the floor,  \n",
      "And I covered her up and then  \n",
      "Thought I'd go look through her drawer.  \n",
      "  \n",
      "And when I was through  \n",
      "I filled up my shoe and brought it to you.  \n",
      "And you, you took me in,  \n",
      "You loved me then, you never wasted time.  \n",
      "And I, I never took much,  \n",
      "I never asked for your crutch  \n",
      "And I don't ask for mine.\n",
      "\n",
      "\n",
      "\n",
      "Song after preprocessing (truncated after 200 words)\n",
      "--------------------------------------------------------------------------------\n",
      "[  29   35   86   22  930   18  329  386   24  676    2  460   35   30 2314\n",
      "    4   35 2112   12    9  174  354 1132    9  125  112   86   44  365    3\n",
      "   34  172   11   30  112   13    2   34   47    5  203   21   35   86   22\n",
      "  324  424  173  137  152   78   19  152   50   61    2  800   66    4 3705\n",
      "    2 4921   12   43 2606    4  778   43   82   53    4   35 4922   43 3019\n",
      "    4 4923   43 1662  112   35   86   22   61 2607   26    2 3020    9  394\n",
      "    8    9 1780    4  524   25    9 4924    4 4925 3706   43    9  382  146\n",
      " 1663   10 3707   35  853    7  581    2  800    8    1  963   74 4926  398\n",
      "    4  178 2608  131 1133    9 2609    2  325   78    4 1664    2 1557    8\n",
      "    1 2610   35  325    5   61   11    4    2  357    5   91 2113   48   10\n",
      "   13 1388   10    3    8   18 4927   13 4928   47  801   43 4929 3021    4\n",
      "   29   35  140   53    2  778   43   19  113   35   86   31  714    2   86\n",
      "   18  329 1920  779  326  144 4930   48   18 3707   35 4931  317   43  174\n",
      "   34   26  537  112   35]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from helper import words_to_index\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "X, index, reverse_index = words_to_index(data, \"text\", max_words=5000, length=200)\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(data[\"artist\"])\n",
    "\n",
    "# Dump preprocessed data to disk\n",
    "with open(\"./preprocessed_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump((X, y, index, reverse_index, lb), f)\n",
    "\n",
    "print(\"\\nExample song before preprocessing\")\n",
    "print(\"-\" * 80)\n",
    "print(data.at[0, \"text\"])\n",
    "\n",
    "print(\"\\nSong after preprocessing (truncated after 200 words)\")\n",
    "print(\"-\" * 80)\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Iteration (Checkpoint)\n",
    "---\n",
    "For the first iteration of the model, I start with an embedding layer, followed by an LSTM layer and a Dense layer. I do not use dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_23 (Embedding)     (None, 200, 8)            40000     \n",
      "_________________________________________________________________\n",
      "lstm_23 (LSTM)               (None, 20)                2320      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 42,425\n",
      "Trainable params: 42,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 754 samples, validate on 189 samples\n",
      "Epoch 1/10\n",
      "754/754 [==============================] - 4s - loss: 1.6057 - acc: 0.2334 - val_loss: 1.5979 - val_acc: 0.2434\n",
      "Epoch 2/10\n",
      "754/754 [==============================] - 5s - loss: 1.5895 - acc: 0.3196 - val_loss: 1.5617 - val_acc: 0.2910\n",
      "Epoch 3/10\n",
      "754/754 [==============================] - 5s - loss: 1.5667 - acc: 0.2706 - val_loss: 1.5452 - val_acc: 0.2963\n",
      "Epoch 4/10\n",
      "754/754 [==============================] - 5s - loss: 1.5513 - acc: 0.3024 - val_loss: 1.5387 - val_acc: 0.2804\n",
      "Epoch 5/10\n",
      "754/754 [==============================] - 5s - loss: 1.4858 - acc: 0.3382 - val_loss: 1.5181 - val_acc: 0.3280\n",
      "Epoch 6/10\n",
      "754/754 [==============================] - 4s - loss: 1.3805 - acc: 0.3687 - val_loss: 1.6183 - val_acc: 0.3016\n",
      "Epoch 7/10\n",
      "754/754 [==============================] - 4s - loss: 1.3521 - acc: 0.3740 - val_loss: 1.5201 - val_acc: 0.2963\n",
      "Epoch 8/10\n",
      "754/754 [==============================] - 5s - loss: 1.3626 - acc: 0.3687 - val_loss: 1.6499 - val_acc: 0.2857\n",
      "Epoch 9/10\n",
      "754/754 [==============================] - 4s - loss: 1.3622 - acc: 0.3767 - val_loss: 1.5249 - val_acc: 0.3386\n",
      "Epoch 10/10\n",
      "754/754 [==============================] - 5s - loss: 1.3245 - acc: 0.3647 - val_loss: 1.6038 - val_acc: 0.2169\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21e9d145470>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Code adapted from http://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pickle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "with open(\"./preprocessed_data.pkl\", \"rb\") as f:\n",
    "    X, y, index, _, _ = pickle.load(f)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "embedding_vector_length = 8\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(index), embedding_vector_length, input_length=200))\n",
    "model.add(LSTM(20))\n",
    "model.add(Dense(5, activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model achieves a maximum accuracy score of 33.86% on the validation set, and starts overfitting after the fifth epoch. Reducing the model's complexity even further does not improve generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Iteration (Checkpoint)\n",
    "---\n",
    "Now let's try to add dropout on the LSTM layer's input and output to try to mitigate overfitting. I also increase the learning rate by an order of magnitude and add some decay, following the suggestions in [this](http://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/) article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_29 (Embedding)     (None, 200, 8)            40000     \n",
      "_________________________________________________________________\n",
      "lstm_29 (LSTM)               (None, 24)                3168      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 5)                 125       \n",
      "=================================================================\n",
      "Total params: 43,293\n",
      "Trainable params: 43,293\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 754 samples, validate on 189 samples\n",
      "Epoch 1/10\n",
      "754/754 [==============================] - 9s - loss: 1.6091 - acc: 0.2308 - val_loss: 1.5604 - val_acc: 0.2751\n",
      "Epoch 2/10\n",
      "754/754 [==============================] - 8s - loss: 1.5575 - acc: 0.2772 - val_loss: 1.5500 - val_acc: 0.2646\n",
      "Epoch 3/10\n",
      "754/754 [==============================] - 8s - loss: 1.5334 - acc: 0.3289 - val_loss: 1.5169 - val_acc: 0.3386\n",
      "Epoch 4/10\n",
      "754/754 [==============================] - 8s - loss: 1.5084 - acc: 0.3554 - val_loss: 1.5433 - val_acc: 0.2487\n",
      "Epoch 5/10\n",
      "754/754 [==============================] - 8s - loss: 1.4617 - acc: 0.3687 - val_loss: 1.5221 - val_acc: 0.2857\n",
      "Epoch 6/10\n",
      "754/754 [==============================] - 9s - loss: 1.4257 - acc: 0.3886 - val_loss: 1.5269 - val_acc: 0.2804\n",
      "Epoch 7/10\n",
      "754/754 [==============================] - 9s - loss: 1.4178 - acc: 0.4191 - val_loss: 1.5258 - val_acc: 0.2804\n",
      "Epoch 8/10\n",
      "754/754 [==============================] - 10s - loss: 1.3748 - acc: 0.4045 - val_loss: 1.5272 - val_acc: 0.2646\n",
      "Epoch 9/10\n",
      "754/754 [==============================] - 8s - loss: 1.3634 - acc: 0.4324 - val_loss: 1.5244 - val_acc: 0.3016\n",
      "Epoch 10/10\n",
      "754/754 [==============================] - 9s - loss: 1.3428 - acc: 0.4111 - val_loss: 1.5193 - val_acc: 0.2751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2202b98b390>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pickle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "with open(\"./preprocessed_data.pkl\", \"rb\") as f:\n",
    "    X, y, index, _, _ = pickle.load(f)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "embedding_vector_length = 8\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(index), embedding_vector_length, input_length=200))\n",
    "model.add(LSTM(24, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(5, activation=\"softmax\"))\n",
    "opt = optimizers.Adam(lr=0.01, decay=0.05)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With dropout, the model achieves a maximum accuracy score of 33.86%, and starts overfitting after the fourth epoch. Tuning dropout rate, number of nodes in the LSTM layer, learning rate or decay doesn't significantly improve results. We most likely don't have enough data for dropout to help generalize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Third Iteration (Checkpoint)\n",
    "---\n",
    "For the third and final iteration, let's add a convolutional layer and max pooling to see if we can improve accuracy further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_31 (Embedding)     (None, 200, 8)            40000     \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 200, 8)            200       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 100, 8)            0         \n",
      "_________________________________________________________________\n",
      "lstm_31 (LSTM)               (None, 20)                2320      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 42,625\n",
      "Trainable params: 42,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 754 samples, validate on 189 samples\n",
      "Epoch 1/10\n",
      "754/754 [==============================] - 6s - loss: 1.6091 - acc: 0.1963 - val_loss: 1.6074 - val_acc: 0.1852\n",
      "Epoch 2/10\n",
      "754/754 [==============================] - 6s - loss: 1.6045 - acc: 0.2321 - val_loss: 1.6029 - val_acc: 0.1799\n",
      "Epoch 3/10\n",
      "754/754 [==============================] - 6s - loss: 1.5917 - acc: 0.2918 - val_loss: 1.5864 - val_acc: 0.2169\n",
      "Epoch 4/10\n",
      "754/754 [==============================] - 6s - loss: 1.5421 - acc: 0.2944 - val_loss: 1.5328 - val_acc: 0.2963\n",
      "Epoch 5/10\n",
      "754/754 [==============================] - 5s - loss: 1.3990 - acc: 0.4058 - val_loss: 1.5138 - val_acc: 0.3492\n",
      "Epoch 6/10\n",
      "754/754 [==============================] - 5s - loss: 1.2760 - acc: 0.4801 - val_loss: 1.6654 - val_acc: 0.3439\n",
      "Epoch 7/10\n",
      "754/754 [==============================] - 5s - loss: 1.2623 - acc: 0.4748 - val_loss: 1.5486 - val_acc: 0.3333\n",
      "Epoch 8/10\n",
      "754/754 [==============================] - 5s - loss: 1.2072 - acc: 0.4894 - val_loss: 1.6178 - val_acc: 0.3122\n",
      "Epoch 9/10\n",
      "754/754 [==============================] - 6s - loss: 1.1949 - acc: 0.4987 - val_loss: 1.7183 - val_acc: 0.3492\n",
      "Epoch 10/10\n",
      "754/754 [==============================] - 6s - loss: 1.1372 - acc: 0.5040 - val_loss: 1.9947 - val_acc: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x221bfe08d30>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pickle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "with open(\"./preprocessed_data.pkl\", \"rb\") as f:\n",
    "    X, y, index, _, _ = pickle.load(f)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "embedding_vector_length = 8\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(index), embedding_vector_length, input_length=200))\n",
    "model.add(Conv1D(filters=8, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(20))\n",
    "model.add(Dense(5, activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version of the model achieves a maximum accuracy of 34.92%, and overfits after the fourth epoch. Interestingly, validation loss is the highest out of either past iteration, an even starts increasing after the fifth epoch although validation accuracy doesn't drop. I would not consider this an improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Final Model Evaluation (Checkpoint)\n",
    "---\n",
    "Because all of the models yielded similar results, I decide to go with the first, simplest iteration of the model. It seems that adding dropout and convolutional layers only causes the model to overfit more quickly and does little to improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_27 (Embedding)     (None, 200, 8)            40000     \n",
      "_________________________________________________________________\n",
      "lstm_27 (LSTM)               (None, 20)                2320      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 42,425\n",
      "Trainable params: 42,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 754 samples, validate on 189 samples\n",
      "Epoch 1/5\n",
      "754/754 [==============================] - 5s - loss: 1.6050 - acc: 0.2520 - val_loss: 1.5966 - val_acc: 0.2540\n",
      "Epoch 2/5\n",
      "754/754 [==============================] - 6s - loss: 1.5878 - acc: 0.2984 - val_loss: 1.5567 - val_acc: 0.2963\n",
      "Epoch 3/5\n",
      "754/754 [==============================] - 6s - loss: 1.5626 - acc: 0.2639 - val_loss: 1.5445 - val_acc: 0.3069\n",
      "Epoch 4/5\n",
      "754/754 [==============================] - 5s - loss: 1.5395 - acc: 0.2878 - val_loss: 1.5263 - val_acc: 0.2910\n",
      "Epoch 5/5\n",
      "754/754 [==============================] - 5s - loss: 1.4795 - acc: 0.3462 - val_loss: 1.5682 - val_acc: 0.2698\n",
      "Train on 754 samples, validate on 189 samples\n",
      "Epoch 1/5\n",
      "754/754 [==============================] - 6s - loss: 1.6030 - acc: 0.2692 - val_loss: 1.6098 - val_acc: 0.2011\n",
      "Epoch 2/5\n",
      "754/754 [==============================] - 6s - loss: 1.5843 - acc: 0.3037 - val_loss: 1.6090 - val_acc: 0.2222\n",
      "Epoch 3/5\n",
      "754/754 [==============================] - 5s - loss: 1.5534 - acc: 0.3143 - val_loss: 1.6142 - val_acc: 0.2804\n",
      "Epoch 4/5\n",
      "754/754 [==============================] - 6s - loss: 1.5397 - acc: 0.2692 - val_loss: 1.6003 - val_acc: 0.2751\n",
      "Epoch 5/5\n",
      "754/754 [==============================] - 5s - loss: 1.4966 - acc: 0.3130 - val_loss: 1.7352 - val_acc: 0.3016\n",
      "Train on 754 samples, validate on 189 samples\n",
      "Epoch 1/5\n",
      "754/754 [==============================] - 5s - loss: 1.6047 - acc: 0.2679 - val_loss: 1.5989 - val_acc: 0.2222\n",
      "Epoch 2/5\n",
      "754/754 [==============================] - 5s - loss: 1.5834 - acc: 0.2785 - val_loss: 1.5741 - val_acc: 0.2275\n",
      "Epoch 3/5\n",
      "754/754 [==============================] - 5s - loss: 1.5556 - acc: 0.2798 - val_loss: 1.5724 - val_acc: 0.2222\n",
      "Epoch 4/5\n",
      "754/754 [==============================] - 5s - loss: 1.5350 - acc: 0.2878 - val_loss: 1.5610 - val_acc: 0.2381\n",
      "Epoch 5/5\n",
      "754/754 [==============================] - 5s - loss: 1.4711 - acc: 0.3395 - val_loss: 1.5828 - val_acc: 0.2434\n",
      "Train on 755 samples, validate on 188 samples\n",
      "Epoch 1/5\n",
      "755/755 [==============================] - 5s - loss: 1.6043 - acc: 0.2424 - val_loss: 1.6099 - val_acc: 0.1277\n",
      "Epoch 2/5\n",
      "755/755 [==============================] - 6s - loss: 1.5844 - acc: 0.2715 - val_loss: 1.6056 - val_acc: 0.2872\n",
      "Epoch 3/5\n",
      "755/755 [==============================] - 6s - loss: 1.5575 - acc: 0.2702 - val_loss: 1.5856 - val_acc: 0.2766\n",
      "Epoch 4/5\n",
      "755/755 [==============================] - 5s - loss: 1.5415 - acc: 0.2675 - val_loss: 1.5898 - val_acc: 0.2979\n",
      "Epoch 5/5\n",
      "755/755 [==============================] - 6s - loss: 1.4864 - acc: 0.3073 - val_loss: 1.6132 - val_acc: 0.2872\n",
      "Train on 755 samples, validate on 188 samples\n",
      "Epoch 1/5\n",
      "755/755 [==============================] - 5s - loss: 1.6055 - acc: 0.2596 - val_loss: 1.5999 - val_acc: 0.2500\n",
      "Epoch 2/5\n",
      "755/755 [==============================] - 6s - loss: 1.5868 - acc: 0.2715 - val_loss: 1.5710 - val_acc: 0.2606\n",
      "Epoch 3/5\n",
      "755/755 [==============================] - 5s - loss: 1.5503 - acc: 0.2742 - val_loss: 1.5403 - val_acc: 0.2606\n",
      "Epoch 4/5\n",
      "755/755 [==============================] - 5s - loss: 1.4918 - acc: 0.3272 - val_loss: 1.5724 - val_acc: 0.2979\n",
      "Epoch 5/5\n",
      "755/755 [==============================] - 5s - loss: 1.3960 - acc: 0.3682 - val_loss: 1.5417 - val_acc: 0.3245\n",
      "\n",
      "Average accuracy score: 28.53%\n",
      "Standard deviation of accuracy scores: 2.76\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pickle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "with open(\"./preprocessed_data.pkl\", \"rb\") as f:\n",
    "    X, y, index, _, lb = pickle.load(f)\n",
    "\n",
    "embedding_vector_length = 8\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(index), embedding_vector_length, input_length=200))\n",
    "model.add(LSTM(20))\n",
    "model.add(Dense(5, activation=\"softmax\"))\n",
    "print(model.summary())\n",
    "\n",
    "# Save initial weights so we can reset them before each validation session\n",
    "model.save_weights(\"final_model_weights.h5\")\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scores = []\n",
    "\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    model.load_weights(\"final_model_weights.h5\")\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=32)\n",
    "    scores.append(model.evaluate(X_test, y_test, verbose=0)[1])\n",
    "    \n",
    "print(\"\\nAverage accuracy score: {:.2f}%\".format(np.mean(scores) * 100))\n",
    "print(\"Standard deviation of accuracy scores: {:.2f}\".format(np.std(scores) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
